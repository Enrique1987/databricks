{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a97dda72",
   "metadata": {},
   "source": [
    "## Model Selection with Hyperopt & MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b829befe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from hyperopt import fmin, tpe, hp, SparkTrials, STATUS_OK, Trials\n",
    "\n",
    "import mlflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458a6fb9",
   "metadata": {},
   "source": [
    "### California housing dataset\n",
    "\n",
    "- The California housing dataset is a widely used dataset in machine learning and is available in the scikit-learn library\n",
    "- It contains information about housing prices in various districts of California. The dataset is often used for regression tasks to predict the median house value in a given district based on several features.\n",
    "\n",
    "- **The California housing dataset provides the following information for each district:**\n",
    "\n",
    "1) MedInc: Median income of households in the district.\n",
    "2) HouseAge: Median age of houses in the district.\n",
    "3) AveRooms: Average number of rooms per house.\n",
    "4) AveBedrms: Average number of bedrooms per house.\n",
    "5) Population: Total population in the district.\n",
    "6) AveOccup: Average number of occupants per house.\n",
    "7) Latitude: Latitude of the district's location.\n",
    "8) Longitude: Longitude of the district's location.\n",
    "9) MedHouseVal: Median value of houses in the district (the target variable).\n",
    "\n",
    "- The goal of using this dataset is typically to build a regression model that can predict the median house value based on the given features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffb97756",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = fetch_california_housing(return_X_y=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9b0819",
   "metadata": {},
   "source": [
    "### Feature engineering \n",
    "##### Scale the features\n",
    "\n",
    "Its the process of transformation numerical features in a dataset to a common scale. Its a crucial stept in data pre-procesing, help to bring the features to similar range of magnitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93c81d30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6.60969987e-17,  5.50808322e-18,  6.60969987e-17, -1.06030602e-16,\n",
       "       -1.10161664e-17,  3.44255201e-18, -1.07958431e-15, -8.52651283e-15])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X.mean(axis=0)\n",
    "scalar = StandardScaler()\n",
    "X = scalar.fit_transform(X)\n",
    "X.mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7d125a",
   "metadata": {},
   "source": [
    "#### Convert the numeric target column to discrete values\n",
    "\n",
    "Refers to the process of transforming a target variable that originally contains continuous numeric data into discrete categories. This process is typically done through techniques such as binning or quantization.\n",
    "\n",
    "**Binning**: This involves grouping a range of continuous values into bins or categories. For instance, ages in a dataset could be converted from numerical values like 22, 34, 45, etc., into categorical bins such as '20-29', '30-39', '40-49'.  \n",
    "**Quantization**: This method assigns each continuous value to a discrete class that represents a range or a specific condition. For example, converting a continuous income variable into 'low', 'medium', and 'high' income categories based on predefined income thresholds.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bae99b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_discrete = np.where(y < np.median(y), 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f877ed48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(y_discrete)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a679c1c",
   "metadata": {},
   "source": [
    "\n",
    "### Hyperopt workflow\n",
    "#### Define the function to minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b41474d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    classifier_type = params['type']\n",
    "    del params['type']\n",
    "    if classifier_type == 'svm':\n",
    "        clf = SVC(**params)\n",
    "    elif classifier_type == 'rf':\n",
    "        clf = RandomForestClassifier(**params)\n",
    "    elif classifier_type == 'logreg':\n",
    "        clf = LogisticRegression(**params)\n",
    "    else:\n",
    "        return 0\n",
    "    accuracy = cross_val_score(clf, X, y_discrete).mean()\n",
    "    \n",
    "    # Because fmin() tries to minimize the objective, this function must return the negative accuracy. \n",
    "    return {'loss': -accuracy, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352c35af",
   "metadata": {},
   "source": [
    "#### Define the search space over hyperparameters\n",
    "**search space** refers to the set of all possible configurations, solutions, or parameter sets that a model or algorithm can explore to find the optimal solution.\n",
    "\n",
    "#### Select the search algorithm\n",
    "\n",
    "The two main choices are:\n",
    "* `hyperopt.tpe.suggest`: Tree of Parzen Estimators, a Bayesian approach that iteratively and adaptively selects new hyperparameter settings to explore based on previous results\n",
    "* `hyperopt.rand.suggest`: Random search, a non-adaptive approach that samples over the search space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fcd8e985",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████| 32/32 [09:36<00:00, 18.02s/trial, best loss: -0.8375968992248062]\n"
     ]
    }
   ],
   "source": [
    "from hyperopt import fmin, tpe, hp, Trials, STATUS_OK\n",
    "\n",
    "search_space = hp.choice('classifier_type', [\n",
    "    {\n",
    "        'type': 'svm',\n",
    "        'C': hp.lognormal('SVM_C', 0, 1.0),\n",
    "        'kernel': hp.choice('kernel', ['linear', 'rbf'])\n",
    "    },\n",
    "    {\n",
    "        'type': 'rf',\n",
    "        'max_depth': hp.choice('max_depth', [int(x) for x in np.arange(2, 6, 1)]),  # Ensure max_depth is an integer\n",
    "        'criterion': hp.choice('criterion', ['gini', 'entropy'])\n",
    "    },\n",
    "    {\n",
    "        'type': 'logreg',\n",
    "        'C': hp.lognormal('LR_C', 0, 1.0),\n",
    "        'solver': hp.choice('solver', ['liblinear', 'lbfgs'])\n",
    "    },\n",
    "])\n",
    "\n",
    "\n",
    "# Set your algorithm to use for hyperparameter optimization\n",
    "algo = tpe.suggest\n",
    "\n",
    "# Initialize Trials object\n",
    "trials = Trials()\n",
    "\n",
    "# Start the MLflow run and hyperparameter optimization\n",
    "import mlflow\n",
    "\n",
    "with mlflow.start_run():\n",
    "    best_results = fmin(\n",
    "        fn=objective,\n",
    "        space=search_space,\n",
    "        algo=algo,\n",
    "        max_evals=32,\n",
    "        trials=trials  # Use the initialized Trials object here\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920a24fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
