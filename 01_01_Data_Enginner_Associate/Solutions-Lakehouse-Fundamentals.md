**Which of the following describes how the Databricks Lakehouse Platform makes data governance simpler? Select one response.**


&nbsp;&nbsp;&nbsp;&nbsp;A.Unity Catalog provides a different governance solution for each major Databricks Lakehouse Platform Service.

&nbsp;&nbsp;&nbsp;&nbsp;B.Unity Catalog provides a different governance solution for each workload.

&nbsp;&nbsp;&nbsp;&nbsp;C.Unity Catalog provides a single governance solution across workload types and clouds.

&nbsp;&nbsp;&nbsp;&nbsp;D.Unity Catalog provides a single governance solution fully managed by the Databricks team.

&nbsp;&nbsp;&nbsp;&nbsp;E.Unity Catalog provides a different governance solution for each cloud. 

Solution

&nbsp;&nbsp;&nbsp;&nbsp;C 

**Which of the following architecture benefits is provided directly by the Databricks Lakehouse Platform? Select three responses.**

&nbsp;&nbsp;&nbsp;&nbsp;A.Efficient on-premises optimized hardware

&nbsp;&nbsp;&nbsp;&nbsp;B.Available on and across multiple clouds

&nbsp;&nbsp;&nbsp;&nbsp;C.Built on open source and open standards

&nbsp;&nbsp;&nbsp;&nbsp;D. Scalable, redundant cloud-based data storage

&nbsp;&nbsp;&nbsp;&nbsp;E.Unified security and governance approach for all data assets

Solution

B, C, E


**Which of the following is a common problem within a data lake architecture that can be easily solved by using the Databricks Lakehouse Platform? Select three responses.**

 

&nbsp;&nbsp;&nbsp;&nbsp;A.Inability to use open-source data formats

&nbsp;&nbsp;&nbsp;&nbsp;B.Ineffective partitioning

&nbsp;&nbsp;&nbsp;&nbsp;C.Lack of ACID transaction support

&nbsp;&nbsp;&nbsp;&nbsp;D.Too many small files

&nbsp;&nbsp;&nbsp;&nbsp;E.Lack of cloud service integrations

Solutions


Solutions B, C, D




**The Databricks Lakehouse Platform architecture consists of a control plane and a data plane.
Which of the following resources exists within the Databricks control plane? Select two responses.**

 
&nbsp;&nbsp;&nbsp;&nbsp;A. Serverless compute resources
&nbsp;&nbsp;&nbsp;&nbsp;B. Cloud object storage
&nbsp;&nbsp;&nbsp;&nbsp;C. Cluster configurations
&nbsp;&nbsp;&nbsp;&nbsp;D. Notebooks
&nbsp;&nbsp;&nbsp;&nbsp;E. Classic compute resources


Solution

C, D


**Which of the following is a benefit of the Databricks Lakehouse Platform being designed to support all data and artificial intelligence (AI) workloads? Select four responses.**

&nbsp;&nbsp;&nbsp;&nbsp;A.Data teams can all utilize secure data from a single source to deliver reliable, consistent results across workloads at scale.  

&nbsp;&nbsp;&nbsp;&nbsp;B.Data analysts, data engineers, and data scientists can easily collaborate within a single platform.  

&nbsp;&nbsp;&nbsp;&nbsp;C.Data workloads can be automatically scaled when needed.  

&nbsp;&nbsp;&nbsp;&nbsp;D.There is increased need for multiple, specialist platform administrators to maintain each component of the unified platform.  

&nbsp;&nbsp;&nbsp;&nbsp;E.Analysts can easily integrate their favorite business intelligence (BI) tools for further analysis.



Solution

A, B, C, E




**Which of the following correctly describes how a specific capability of the Databricks Lakehouse Platform supports a data streaming pattern? Select three responses.**

&nbsp;&nbsp;&nbsp;&nbsp;A.Structured Streaming enables stream-based machine learning inference.

&nbsp;&nbsp;&nbsp;&nbsp;B.Databricks Workflows automatically passes data from task to task in regular microbatches.

&nbsp;&nbsp;&nbsp;&nbsp;C.Auto Loader continuously and incrementally ingests streaming data.

&nbsp;&nbsp;&nbsp;&nbsp;D.MLflow ingests its automatic experiment tracking data into a stream for continuous monitoring.

&nbsp;&nbsp;&nbsp;&nbsp;E.Delta Live Tables processes ETL pipelines on streaming data with advanced monitoring mechanisms.


Solution

A, C, E




**Which of the following describes the motivation for the creation of the data lakehouse? Select one response.**


&nbsp;&nbsp;&nbsp;&nbsp;A.Organizations needed to reduce the costs of storing their open-format data files in the cloud.

&nbsp;&nbsp;&nbsp;&nbsp;B.Organizations needed a reliable data management system with transactional guarantees for their structured data.

&nbsp;&nbsp;&nbsp;&nbsp;C.Organizations needed a way to scale their data lake workloads without investing in additional on-premises hardware.

&nbsp;&nbsp;&nbsp;&nbsp;D.Organizations needed to be able to develop increasingly complex machine learning workloads using a simple, SQL-based solution.

&nbsp;&nbsp;&nbsp;&nbsp;E.Organizations needed a single, flexible, high-performance system to support data, analytics, and machine learning workloads.


Solution
E




**Maintaining and improving data quality is a major goal of modern data engineering.
Which of the following contributes directly to high levels of data quality within the Databricks Lakehouse Platform? Select two responses.**

 

&nbsp;&nbsp;&nbsp;&nbsp;A.Business intelligence (BI) tool integrations

&nbsp;&nbsp;&nbsp;&nbsp;B.Simplified machine learning model serving

&nbsp;&nbsp;&nbsp;&nbsp;C.Table schema evolution

&nbsp;&nbsp;&nbsp;&nbsp;D.Data expectations enforcement

&nbsp;&nbsp;&nbsp;&nbsp;E.Apache Sparkâ€™s data format flexibility



solution

C, D



**In which of the following ways do serverless compute resources differ from classic compute resources within the Databricks Lakehouse Platform? Select two responses.**

&nbsp;&nbsp;&nbsp;&nbsp;A.They exist within the customer cloud account

&nbsp;&nbsp;&nbsp;&nbsp;B.They are located within the cloud

&nbsp;&nbsp;&nbsp;&nbsp;C.They exist within the Databricks cloud account

&nbsp;&nbsp;&nbsp;&nbsp;D.They result in lower costs by not overprovisioning

&nbsp;&nbsp;&nbsp;&nbsp;E.They are always running and reserved for a single, specific customer when needed


Solution 
C, D



**Data organizations need specialized environments designed specifically for machine learning workloads.
Which of the following is made available by Databricks as part of Databricks Machine Learning to support machine learning workloads? Select four responses.**


&nbsp;&nbsp;&nbsp;&nbsp;A.Optimized and preconfigured machine learning frameworks

&nbsp;&nbsp;&nbsp;&nbsp;B.Built-in real-time model serving

&nbsp;&nbsp;&nbsp;&nbsp;C.Support for distributed model training on big data

&nbsp;&nbsp;&nbsp;&nbsp;D.Built-in automated machine learning development

&nbsp;&nbsp;&nbsp;&nbsp;E.Lakehouse-specific deep learning frameworks


Solution

A, B, C, D




**Which of the following data engineering capabilities simplifies the work of data engineers on the Databricks Lakehouse Platform? Select three responses.**

&nbsp;&nbsp;&nbsp;&nbsp;A.SQL and Python development compatibility

&nbsp;&nbsp;&nbsp;&nbsp;B.Automatic deployment and data operations

&nbsp;&nbsp;&nbsp;&nbsp;C.Serverless cluster startup times

&nbsp;&nbsp;&nbsp;&nbsp;D.End-to-end data pipeline visibility

&nbsp;&nbsp;&nbsp;&nbsp;E.Flexible machine learning development solutions


Solution
A, B, D


**One of the foundational technologies provided by the Databricks Lakehouse Platform is an open-source, file-based storage format that provides a number of benefits. These benefits include ACID transaction guarantees, scalable data and metadata handling, audit history and time travel, table schema enforcement and schema evolution, support for deletes/updates/merges, and unified streaming and batch data processing.
Which of the following technologies is being described in the above statement? Select one response.**

 

 


&nbsp;&nbsp;&nbsp;&nbsp;A.Delta Lake

&nbsp;&nbsp;&nbsp;&nbsp;B.Apache Spark

&nbsp;&nbsp;&nbsp;&nbsp;C.MLflow

&nbsp;&nbsp;&nbsp;&nbsp;D.Photon

&nbsp;&nbsp;&nbsp;&nbsp;E.Unity Catalog


Solution
A


**Which of the following compute resources is available in the Databricks Lakehouse Platform? Select two responses.**

&nbsp;&nbsp;&nbsp;&nbsp;A.Local Databricks SQL warehouses

&nbsp;&nbsp;&nbsp;&nbsp;B.On-premises clusters

&nbsp;&nbsp;&nbsp;&nbsp;C.Classic clusters

&nbsp;&nbsp;&nbsp;&nbsp;D.Serverless clusters

&nbsp;&nbsp;&nbsp;&nbsp;E.Serverless Databricks SQL warehouses

Solution
C, E




**A data architect is evaluating data warehousing solutions for their organization to use. As a part of this, the architect is considering the Databricks Lakehouse Platform.
Which of the following is a benefit of using the Databricks Lakehouse Platform for warehousing? Select four responses.**

 

&nbsp;&nbsp;&nbsp;&nbsp;A. A rich ecosystem of business intelligence (BI) integrations
&nbsp;&nbsp;&nbsp;&nbsp;B. Engineering capabilities supporting warehouse source data
&nbsp;&nbsp;&nbsp;&nbsp;C. Built-in governance for single-source-of-truth data
&nbsp;&nbsp;&nbsp;&nbsp;D. Best available price/performance
&nbsp;&nbsp;&nbsp;&nbsp;E. Local development software to integrate with other capabilities

Solution
A, B, C, D



**It can be challenging for a data lakehouse to provide both performance and scalability for all of its query-based workloads to the standards of a data warehouse and a data lake. As a result, Databricks has introduced a technology built atop Apache Spark to further speed up and scale these varied workloads.
Which of the following technologies is being described in the above statement? Select one response.**

 


&nbsp;&nbsp;&nbsp;&nbsp;A. AutoML

&nbsp;&nbsp;&nbsp;&nbsp;B. Unity Catalog

&nbsp;&nbsp;&nbsp;&nbsp;C. Delta Lake

&nbsp;&nbsp;&nbsp;&nbsp;D. Photon

&nbsp;&nbsp;&nbsp;&nbsp;E. AutoML

Solution
D

**In the past, a lot of data engineering resources needed to be contributed to the development of tooling and other mechanisms for creating and managing data workloads. In response, Databricks developed and released a declarative ETL framework so data engineers can focus on helping their organizations get value from their data, Which of the following technologies is being described above? Select one response.**

 


&nbsp;&nbsp;&nbsp;&nbsp;A. Delta Live Tables

&nbsp;&nbsp;&nbsp;&nbsp;B. Databricks SQL Queries

&nbsp;&nbsp;&nbsp;&nbsp;C. Autologging

&nbsp;&nbsp;&nbsp;&nbsp;D. Delta Lake

&nbsp;&nbsp;&nbsp;&nbsp;E. Databricks Jobs

*Solution*
A

Which of the following describes what challenges a data organization would likely face when migrating from a data warehouse to a data lake? Select two responses.

&nbsp;&nbsp;&nbsp;&nbsp;A.There are increased cloud storage costs in a data lake.

&nbsp;&nbsp;&nbsp;&nbsp;B.There are increased security and privacy concerns in a data lake.

&nbsp;&nbsp;&nbsp;&nbsp;C.There are increased data reliability issues in a data lake.

&nbsp;&nbsp;&nbsp;&nbsp;D.There are increased data quality guarantees in a data lake

&nbsp;&nbsp;&nbsp;&nbsp;E.There are increased performance speeds in a data lake.


*Solution*
B, C


**Which of the following Databricks Lakehouse Platform services or capabilities provides a data warehousing experience to its users? Select one response.**


&nbsp;&nbsp;&nbsp;&nbsp;A. Databricks Machine Learning

&nbsp;&nbsp;&nbsp;&nbsp;B. Delta Lake

&nbsp;&nbsp;&nbsp;&nbsp;C. Data Science and Engineering Workspace

&nbsp;&nbsp;&nbsp;&nbsp;D. Databricks SQL

&nbsp;&nbsp;&nbsp;&nbsp;E. Unity Catalog

Solution
D


**Which of the following do Databricks SQL users experience when using serverless Databricks SQL warehouses rather than classic Databricks SQL warehouses? Select one response.**


&nbsp;&nbsp;&nbsp;&nbsp;A. Availability of Photon

&nbsp;&nbsp;&nbsp;&nbsp;B. Availability of automatic scaling

&nbsp;&nbsp;&nbsp;&nbsp;C. Increased total cost of use

&nbsp;&nbsp;&nbsp;&nbsp;D. Expedited environment startup

&nbsp;&nbsp;&nbsp;&nbsp;E. Performance degradation on long-running queries

Solution
D

**Data sharing has traditionally been performed by proprietary vendor solutions, SSH File Transfer Protocol (SFTP), or cloud-specific solutions. However, each of these sharing tools and solutions comes with its own set of limitations. As a result, Databricks helped to develop the solution, Delta Sharing.
Which of the following describes Delta Sharing as a solution for data sharing? Select one response.**

 


&nbsp;&nbsp;&nbsp;&nbsp;A. Delta Sharing is a multicloud, proprietary solution for efficiently copying and transferring data from the lakehouse to any external system.

&nbsp;&nbsp;&nbsp;&nbsp;B. Delta Sharing is a multicloud, open-source solution for distributing data across a number of compute resources for efficient data shuffling.

&nbsp;&nbsp;&nbsp;&nbsp;C. Delta Sharing is a multicloud, proprietary solution to securely and efficiently share data while maintaining control of the source data.

&nbsp;&nbsp;&nbsp;&nbsp;D. Delta Sharing is a multicloud, open-source solution to securely and efficiently share live data from the lakehouse to any external system.

&nbsp;&nbsp;&nbsp;&nbsp;E. Delta Sharing is a multicloud, open-source solution to share data between Databricks workspaces within a single Databricks account.

Solution
D

**Which of the following is a benefit of using Databricks Workflows for orchestration purposes? Select two responses.**

 

&nbsp;&nbsp;&nbsp;&nbsp;A. Databricks Workflows supports tasks for data ingestion, data engineering, machine learning, and business intelligence (BI)Databricks 

&nbsp;&nbsp;&nbsp;&nbsp;B. Workflows supports automating workloads as long as they are not in notebooksDatabricks Workflows provides multiple-task workflow functionality only for Delta Live Tables workloadsDatabricks 

&nbsp;&nbsp;&nbsp;&nbsp;C. Workflows provides Git-backed version control capabilities to notebooks

&nbsp;&nbsp;&nbsp;&nbsp;D. Databricks Workflows supports workloads across multiple cloud service providers and tools


Solution
A, C


**Unity Catalog offers improved Lakehouse data object governance and organization capabilities for data segregation.
Which of the following is a consequence of using Unity Catalog to manage, organize and segregate data objects? Select one response.**


&nbsp;&nbsp;&nbsp;&nbsp;A. Catalogs exist within schemas (databases)

&nbsp;&nbsp;&nbsp;&nbsp;B. Data in tables and views must be stored in external storage locations

&nbsp;&nbsp;&nbsp;&nbsp;C. Views are made available outside of their schemas (databases)

&nbsp;&nbsp;&nbsp;&nbsp;D. Complete data object referencing requires three levels

&nbsp;&nbsp;&nbsp;&nbsp;E. Table metadata is required


*Solution*
D